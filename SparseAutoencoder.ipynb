{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1pYvKa04N1aUyVYrIUz1kjs57mxEN-FAo",
      "authorship_tag": "ABX9TyNHay5fTTA/9mTwU494fJNp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SukhBhagsar/SukhBhagsar/blob/main/SparseAutoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from skimage import io\n"
      ],
      "metadata": {
        "id": "RYJJ39CMLd4W"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading dataset\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/facedetectionDS.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('extracted_dataset/')"
      ],
      "metadata": {
        "id": "d-J7u9PHT4hl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading images from directories\n",
        "def load_images(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = load_img(os.path.join(folder, filename), color_mode=\"grayscale\", target_size=(64, 64))\n",
        "        img_array = img_to_array(img)\n",
        "        images.append(img_array)\n",
        "    return np.array(images)\n",
        "\n",
        "# Loading images from the given datset\n",
        "faces_data = '/content/extracted_dataset/facedetectionDS/faces'\n",
        "non_faces_data = '/content/extracted_dataset/facedetectionDS/notfaces'\n",
        "\n",
        "# Loading and preprocessing images\n",
        "faces_data = load_images(faces_data)\n",
        "non_faces_data = load_images(non_faces_data)\n",
        "\n",
        "# Combining face and non-face data\n",
        "X = np.concatenate((faces_data, non_faces_data), axis=0)\n",
        "\n",
        "# Normalizing  pixel values  between 0 and 1\n",
        "X = X.astype('float32') / 255.\n",
        "\n",
        "# Flattening image data  into vectors\n",
        "X = X.reshape((len(X), np.prod(X.shape[1:])))\n",
        "\n",
        "# Creating labels for faces (1) and non-faces (0)\n",
        "y_faces = np.ones(len(faces_data))\n",
        "y_non_faces = np.zeros(len(non_faces_data))\n",
        "\n",
        "# Combining label\n",
        "y = np.concatenate((y_faces, y_non_faces), axis=0)\n",
        "\n",
        "# Spliting data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "print(\"Training set dimensions:\", X_train.shape)\n",
        "print(\"Testing set dimensions:\", X_test.shape)\n",
        "print(\"Training labels dimensions:\", y_train.shape)\n",
        "print(\"Testing labels dimensions:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ekKU6tYjngJ",
        "outputId": "60883120-d44e-43a1-e104-72fde60531fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set dimensions: (5630, 4096)\n",
            "Testing set dimensions: (1408, 4096)\n",
            "Training labels dimensions: (5630,)\n",
            "Testing labels dimensions: (1408,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Sparse Autoencoder Model\n",
        "def sparse_autoencoder(input_shape, encoding_dim, sparsity_regularizer):\n",
        "    input_image = Input(shape=input_shape)\n",
        "    encoded = Dense(encoding_dim, activation='relu',\n",
        "                    activity_regularizer=regularizers.l1(sparsity_regularizer))(input_image)\n",
        "    decoded = Dense(input_shape[0], activation='sigmoid')(encoded)\n",
        "    autoencoder = Model(input_image, decoded)\n",
        "    return autoencoder\n",
        "input_shape = (4096,)\n",
        "encoding_dim = 32\n",
        "sparsity_regularizer = 0.01\n",
        "\n",
        "autoencoder = sparse_autoencoder(input_shape, encoding_dim, sparsity_regularizer)\n",
        "# Model summary\n",
        "autoencoder.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAwTvSOUkCMu",
        "outputId": "25af44ac-6167-41f0-cf3a-3255447d710d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 4096)]            0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                131104    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4096)              135168    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266272 (1.02 MB)\n",
            "Trainable params: 266272 (1.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing preprocessing images from directories\n",
        "def image_preprocessing(folder, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        image = io.imread(os.path.join(folder, filename))\n",
        "        image = preprocess_image(image)\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "def preprocess_image(image):\n",
        "    # Example: Resize image to (64, 64) and normalize pixel values\n",
        "    image = resize_image(image, target_size=(64, 64))\n",
        "    image = image / 255.0  # Normalize pixel values\n",
        "    return image\n",
        "\n",
        "# Resizing image\n",
        "def resize_image(image, target_size):\n",
        "    # Example: using scikit-image resize function\n",
        "    from skimage.transform import resize\n",
        "    return resize(image, target_size)\n",
        "\n",
        "faces_folder = '/content/extracted_dataset/facedetectionDS/faces'\n",
        "non_faces_folder = '/content/extracted_dataset/facedetectionDS/notfaces'\n",
        "\n",
        "# preprocessing images from both folders\n",
        "faces_images, faces_labels = image_preprocessing(faces_folder, label=1)\n",
        "non_faces_images, non_faces_labels = image_preprocessing(non_faces_folder, label=0)\n",
        "\n",
        "# Combine images and labels from both folders\n",
        "X = np.concatenate((faces_images, non_faces_images), axis=0)\n",
        "y = np.concatenate((faces_labels, non_faces_labels), axis=0)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print shapes of training and testing sets\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tghxjTMep8oS",
        "outputId": "4900ef23-4f3b-485c-8f90-a75128b6ee93"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (5630, 64, 64, 3)\n",
            "Testing set shape: (1408, 64, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Sparse Autoencoder model\n",
        "def sparse_autoencoder(input_shape, encoding_dim):\n",
        "    input_img = Input(shape=input_shape)\n",
        "    encoded = Dense(encoding_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(10e-5))(input_img)\n",
        "    decoded = Dense(3, activation='sigmoid')(encoded)\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "    return autoencoder\n",
        "\n",
        "#  input shape and encoding dimension\n",
        "input_shape = (64, 64, 3)\n",
        "encoding_dim = 32\n",
        "\n",
        "# Creating Sparse Autoencoder model\n",
        "autoencoder = sparse_autoencoder(input_shape, encoding_dim)\n",
        "\n",
        "# Compiling model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Model summary\n",
        "autoencoder.summary()\n",
        "\n",
        "# Training model\n",
        "autoencoder.fit(X_train, X_train,\n",
        "                epochs=5,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, X_test))\n",
        "\n",
        "# Model Evaluation\n",
        "loss = autoencoder.evaluate(X_test, X_test)\n",
        "print(\"Test Loss:\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBAkW-rErPzF",
        "outputId": "b2fee47e-87bc-49e3-9ff9-7d89cb5cdde7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64, 64, 32)        128       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64, 64, 3)         99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 227 (908.00 Byte)\n",
            "Trainable params: 227 (908.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "44/44 [==============================] - 21s 450ms/step - loss: 0.6826 - val_loss: 0.6715\n",
            "Epoch 2/5\n",
            "44/44 [==============================] - 19s 437ms/step - loss: 0.6612 - val_loss: 0.6505\n",
            "Epoch 3/5\n",
            "44/44 [==============================] - 24s 554ms/step - loss: 0.6406 - val_loss: 0.6303\n",
            "Epoch 4/5\n",
            "44/44 [==============================] - 20s 468ms/step - loss: 0.6206 - val_loss: 0.6107\n",
            "Epoch 5/5\n",
            "44/44 [==============================] - 19s 418ms/step - loss: 0.6013 - val_loss: 0.5917\n",
            "44/44 [==============================] - 2s 25ms/step - loss: 0.5917\n",
            "Test Loss: 0.5917243361473083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting encoder and decoder from the autoencoder model\n",
        "encoder_model = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('dense_6').output)\n",
        "decoder_model = Model(inputs=autoencoder.get_layer('dense_7').input, outputs=autoencoder.output)\n",
        "\n",
        "# Encoding images\n",
        "encoded_images = encoder_model.predict(X_test)\n",
        "\n",
        "# Decoding encoded images to generate reconstructed images\n",
        "reconstructed_images = decoder_model.predict(encoded_images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp_0-cGEYl9S",
        "outputId": "4d41fd76-9b57-40aa-9077-cfda5583796a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 [==============================] - 1s 18ms/step\n",
            "44/44 [==============================] - 1s 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_no = 5\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(image_no):\n",
        "    # Displaying Actual images\n",
        "    ax = plt.subplot(2, image_no, i + 1)\n",
        "    plt.imshow(X_test[i].reshape(64, 64, 3))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax.set_title(\"Actual\")\n",
        "\n",
        "    # Displaying reconstructed images or generated faces\n",
        "    ax = plt.subplot(2, image_no, i + 1 + image_no)\n",
        "    plt.imshow(reconstructed_images[i].reshape(64, 64, 3))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax.set_title(\"Generated Face\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "t0sDg5jDZc3V",
        "outputId": "9ae8d4f9-db17-4799-aadb-c306c040a67b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Reshaping original and reconstructed images for compatibility with MSE\n",
        "X_test_reshaped = X_test.reshape(-1, 64*64*3)\n",
        "reconstructed_images_reshaped = reconstructed_images.reshape(-1, 64*64*3)\n",
        "\n",
        "# Calculating MSE\n",
        "mse_loss = mean_squared_error(X_test_reshaped, reconstructed_images_reshaped)\n",
        "print(\"Mean Squared Error Loss:\", mse_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c23Hx69YZ0J5",
        "outputId": "29cc27fb-e3ee-4d55-8042-97269f21b62b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error Loss: 0.1982024439756739\n"
          ]
        }
      ]
    }
  ]
}